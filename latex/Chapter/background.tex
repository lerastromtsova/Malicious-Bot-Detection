\chapter{Background}
\label{ch:background}

\section{Definitions}
\label{sec:definitions}
To introduce the reader to the context of this research, here are the key definitions of terms used throughout this paper. The definitions are either directly cited or rephrased from existing studies. Since a large body of work on social bot detection already exists, the definitions should be carefully picked from the most cited sources in top Computer Science journals. Higher citation scores usually indicate scientists’ trust in a research paper and can be suggestive of the higher quality and importance of a study. Setting a citation threshold to 100 for the bot-related studies, we eliminate the papers that have been cited less than 100 times and thus adhere to more well-known and agreed-upon definitions. However, since modern political events have not yet been described in numerous studies, and information about them is contained in recent papers that do not have a high citation count, no citation threshold is set for them.

Online Social Networks (OSNs), also known as social network sites (SNSs), are ``web-based services that allow individuals to (1) construct a public or semi-public profile within a bounded system, (2) articulate a list of other users with whom they share a connection, and (3) view and traverse their list of connections and those made by others within the system'' \cite{Boyd2007}. With the current development of technology, OSNs can be not only web-based but also mobile-based. However, there is no newer definition that would include the ``mobile'' aspect of OSNs. So, we will use the existing definition but supplement it with the ``mobile'' aspect: ``OSNs are web- or mobile-based services...'' Examples of Online Social Networks include, e.g., Facebook, Twitter, and Instagram; for CIS countries, this list is extended with such platforms as VKontakte and Odnoklassniki.

In OSNs, real users co-exist with automated accounts (social bots). Currently, there is no well-agreed definition of what a Social Bot is \cite{Cresci2020}. Social bot research exists at the intersection of sociology and computer science and is looked at from different perspectives, e.g., social scientists’ perspective or engineering perspective. Some definitions focus on technical details, and some highlight social interaction. However, efforts were made to unify the terminology and outline a common definition for this term. For instance, in \cite{grimme2017social}, the following definition is provided: ``The term `Social Bot' is a superordinate concept which summarises different types of (semi-) automatic agents. These agents are designed to fulfil a specific purpose by means of one- or many-sided communication in online media''. Throughout this thesis, we will adhere to this high-level definition as the most universal and comprehensive.

Social bots have multiple purposes, depending on their creators' goals. One of the types of social bots is Political Bot. This bot type is relevant to the current research, as this study aims to uncover the bots that attempt to influence the political landscape of VKontakte. As stated in \cite{woolley2016automating}, Political Bots are politicised social bots that ``suppress free expression and civic innovation through the demobilisation of activist groups and the suffocation of democratic free speech. They subtly work to manipulate public opinion by giving false impressions of candidate popularity, regime strength and international relations.'' Bots of this type usually express higher activity during important political events, such as elections, political crises, and conflicts.

\section{Related work}
\label{sec:related-work}

Bot detection in general is an established field of research that has been of interest to scientists for over a decade. Researchers regularly publish papers regarding bot detection in the top Computer Science journals and introduce new methods to detect bots based mostly on the recent advances in Deep Learning. When bot detection was yet an emerging area (2010), scientists mostly used supervised machine learning methods that focused on individual accounts and classified them into two categories: a bot or a real user. Research shows that, as bots were becoming more and more sophisticated, the naïve assumptions of early supervised methods ceased to function with the same efficiency \cite{Cresci2020}. Instead, in 2012-2013, new methods for bot detection based on the so-called group approach emerged. In group methods, ``a detector analyzes a group of accounts, looking for traces of coordinated and synchronized behaviours. Large groups of coordinated accounts are more likely to be detected than sophisticated individual bots'' \cite{Cresci2020}. The reason for applying group-based methods is the assumption that bots behave in a coordinated manner more often than human users. Since 2018, most of the published papers in the field of bot detection have made use of group approaches (e.g. \cite{Cresci2020a}). The majority of new models still use the supervised learning approach (\cite{Cresci2020a}), which assumes that ground truth is known and a model can learn based on this ground truth. However, in reality, the verifiability of the ground truth in such research is questionable: labelled data comes from crowdsourcing, meaning that humans label this data. At the same time, humans, according to recent data, are only able to correctly classify bots in 24\% of cases \cite{Cresci2020}. Therefore, unsupervised learning has gained more and more attention in the recent years. Simultaneously, adversarial machine learning methods employing anomaly and peak detection are also on the rise.

A narrower and less popular field of research among computer scientists is bot detection on Russian-language social networks. Only a few papers have been published in recent years regarding this topic, and we were not able to find any of these papers published in major Computer Science journals, e.g. proceedings of ACM, AAAI, ICML or IEEE. Speaking about the topical coverage, the majority of papers published in this area relate to the influence that Russian social bots have on the Western audience. As an example, a recent paper \cite{Rheault2021} explores the impact of social bots on electoral campaigns (primarily the Western ones) and only mentions Russia in the context of interfering with the US 2016 presidential elections. An extensive study of Russian propaganda in Eastern Europe briefly touches on the topic of bots, stating that in 2015, 17,590 accounts on Twitter could be classified as pro-Russian social bots \cite{Helmus2018}. Another paper dedicated to measuring the political orientation of Twitter bots in Russia aims to discover the ratio between pro-Kremlin and pro-opposition bots and analyses the primary topics of the content they produce \cite{Stukal2019}.

Most papers that aim to detect bots in Russian social networks use datasets collected from Twitter. One reason for this could be that Twitter is a social media to which researchers outside Russia have easier access and with which they are more familiar than with originally Russian OSNs. However, taking a look at the statistics of the usage of different social media by the Russian population \cite{Statista}, it can be seen that Twitter only has a penetration rate of 11,7\%. In the meanwhile, VKontakte, a Russian social network platform, boasts a gigantic penetration rate of 76,4\%. Therefore it seems promising to make use of the data offered by this media platform. Surprisingly, to our knowledge, few papers cover bot detection on this platform. An example of bot detection research on VKontakte is \cite{Vasilkova2019}, where the authors present their findings regarding topical coverage of bot-produced content on VKontakte but do not provide enough details for their bot detection model to be reproducible and easily checked.

Overall, the current state of research indicates that even though bot detection is a long-studied area, it still has several unsolved problems. One of them is that old bot detection techniques (based on supervised learning and individual consideration of each user account) became obsolete with the development of more sophisticated bots. There is a need for new bot detection models. These new models draw primarily from the group-based approach and either supervised, unsupervised or adversarial learning. Another challenge is that few scientists research bot detection on the examples of content produced in languages other than English, e.g. Russian. Moreover, even when a paper focuses on Russian content, it still centres around the West-oriented approach, e.g. studying the effect of pro-Kremlin bots on Western society. A large gap exists in the current research, and the recent political events call for closing this gap.
