\chapter{Discussion}
\label{ch:discussion}

As a result of this research, firstly, a dataset of VKontakte discussion around the Russian-Ukrainian armed conflict in 2022 was collected and analysed. Then, three different group-based bot detection models were built and applied to this dataset. The first model is based on friendship relations between users and allows creating of a graph spanning more than 73 thousand users. The second and third models are more granular and are based on less frequent features, such as URL sharing patterns and hashtag sequences. These models cover only a thousand and three hundred users, respectively.

A comparison of the three models in terms of accuracy, precision and recall demonstrates that the URL-sharing model performs best. With an accuracy of 85\%, precision of 83.33\% and recall of 90.91\%, it significantly outperforms both the friendship-relations model and the hashtag-sequences model. This might indicate that the bots used in Russian social networks tend to use URLs in their comments. Specifically, they seem to do so to promote Telegram channels, VKontakte groups and YouTube videos. Exploration of these sources of information reveals that these channels, groups and videos are usually highly biased and expose a strong position, whether a pro-Russian or pro-Ukrainian.  

The developed bot detection model provides insights into the influence of political bots on Russian social networks that align with previous research on political bot detection. Firstly, social bots seem to be influential actors on VKontakte. Their removal from the user network leads to a decrease in the influentialness of the whole network. Secondly, they amplify the sentiments expressed in the comments. After their removal from the user network, the amplitude of negative sentiments expressed in user comments lessens. Overall sentiment, however, slightly increases. Bots influence the overall user network sentiment by leaving strongly negative and positive comments. Potentially, in this way, they can manipulate social network users' emotions. This aligns with the findings of previous studies for other social networks and supports the idea that bot behaviour on VKontakte is similar to Twitter bots' behaviour. 

To evaluate the efficiency of the models, crowdsourced labelling of three different database samples was used. The labelling process itself revealed interesting insights into human judgment of bots. The majority of respondents considered pictures, and especially avatar photos, when trying to identify whether a given VKontakte user is a bot. However, with the current progress in image generation algorithms, pictures should not be considered a reliable sign of a real human profile. Attracting attention to the problem of social political bots is crucial to make social network users aware of the various features that can be indicative of bots, such as frequent URL sharing. 

The bot detection model was used as a base for a web application that allows any user on the Internet to bot-check a given VKontakte user and can increase awareness in the Russian-speaking community about the political social bots in OSNs. The web application is publicly available and exposes the results of this work to a wide audience. Not only can it help users distinguish bots and humans on VKontakte, but it also attracts attention to the problem of social political bots and potentially can help decrease their influence in social networks and make Russian-speaking social platforms more transparent, objective and safe. 

